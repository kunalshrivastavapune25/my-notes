CLF C02
40 aws services (200+ available)

Q1. The Deployment Models of the Cloud
	Private Cloud:
		• Cloud services used by a single organization, not exposed to the public.
			EG. ROCKSPACE
	Public Cloud:
		• Cloud resources owned and operated by a thirdparty cloud service provider delivered over the Internet.
		EG. Gogle Cloud, AWS
	Hybrid Cloud:
		• Keep some servers on premises and extend some capabilities to the Cloud

Q2. Problems solved by the Cloud
	• Flexibility: change resource types when needed
	• Cost-Effectiveness: pay as you go, for what you use
	• Scalability: accommodate larger loads by making hardware stronger or adding additional nodes
	• Elasticity: ability to scale out and scale-in when needed
	• High-availability and fault-tolerance: build across data centers
	• Agility: rapidly develop, test and launch software applications


Q7. Types of Cloud Computing
	• Infrastructure as a Service (IaaS)
		• Provide building blocks for cloud IT
		• Provides networking, computers, data storage space
		• Highest level of flexibility
		• Easy parallel with traditional on-premises IT
		• Amazon EC2 (on AWS)
		• GCP, Azure, Rackspace, Digital Ocean, Linode
	• Platform as a Service (PaaS)
		• Removes the need for your organization to manage the underlying infrastructure
		• Focus on the deployment and management of your applications
		• Elastic Beanstalk (on AWS)
		• Heroku, Google App Engine (GCP), Windows Azure (Microsoft)
	• Software as a Service (SaaS)
		• Completed product that is run and managed by the service provider
		• Google Apps (Gmail), Dropbox, Zoom
		• Many AWS services (ex: Rekognition for Machine Learning)
	
		SAAS Manages nothing	
		 IAAS  PAAS     Applications
		 IAAS  PAAS     Data
		 IAAS           Runtime
		 IAAS           Middleware
		 IAAS           O/S
						Virtualization
						Servers
						Storage
						Networking
	
Q8. Pricing of the Cloud – Quick Overview
	• AWS has 3 pricing fundamentals, following the pay-as-you-go pricing
	model
	• Compute:
		• Pay for compute time
	• Storage:
		• Pay for data stored in the Cloud
	• Data transfer OUT of the Cloud:
		• Data transfer IN is free
	• Solves the expensive issue of traditional IT

Q9. AWS Cloud Use Cases
	• AWS enables you to build sophisticated, scalable applications
	• Applicable to a diverse set of industries
	• Use cases include
		• Enterprise IT, Backup & Storage, Big Data analytics
		• Website hosting, Mobile & Social Apps
		• Gaming	


Q10. AWS Global Infrastructure
	• AWS Regions
		• AWS has Regions all around the world
		• Names can be us-east-1, eu-west-3…
		• A region is a cluster of data centers
		• Most AWS services are region-scoped
		How to choose an AWS Region?
			• Compliance with data governance and legal
			requirements: data never leaves a region without
			your explicit permission
			• Proximity to customers: reduced latency
			• Available services within a Region: new services
			and new features aren’t available in every Region
			• Pricing: pricing varies region to region and is
			transparent in the service pricing page
			If you need to launch a new application,
			where should you do it?
	• AWS Availability Zones
		Each region has many availability zones
		(usually 3, min is 3, max is 6). Example:
		• ap-southeast-2a
		• ap-southeast-2b
		• ap-southeast-2c
		• Each availability zone (AZ) is one or more
		discrete data centers with redundant power,
		networking, and connectivity
		• They’re separate from each other, so that
		they’re isolated from disasters
		• They’re connected with high bandwidth,
		ultra-low latency networking
		AWS Region
		Sydney: ap-southeast-2
		ap-southeast-2a
		ap-southeast-2b ap-southeast-2c
	• AWS Data Centers
	• AWS Edge Locations
		Amazon has 400+ Points of Presence (400+ Edge Locations & 10+
		Regional Caches) in 90+ cities across 40+ countries
		• Content is delivered to end users with lower latency


Q11. Tour of the AWS Console
	• AWS has Global Services:
		• Identity and Access Management (IAM)
		• Route 53 (DNS service)
		• CloudFront (Content Delivery Network)
		• WAF (Web Application Firewall)
	• Most AWS services are Region-scoped:
		• Amazon EC2 (Infrastructure as a Service)
		• Elastic Beanstalk (Platform as a Service)
		• Lambda (Function as a Service)
		• Rekognition (Software as a Service)
	

	
Q12. Shared Responsibility Model diagram	
	CUSTOMER = RESPONSIBILITY FOR THE SECURITY IN THE CLOUD
		CUSTOMER DATA , 
		PLATEFORM APPLICATIONS IDENTITY AND ACCESS MANAGEMENT
		OS, network and firewall config
		client side data encryption
		server side data encryption
		network traffice protectioj data encryption
	AWS = RESPONSIBILITY FOR THE SECURITY OF THE CLOUD	
		SOFTWARE -- compute storage database networking
		HARDWARE--REGIONS AVAILABILITY ZONES EDGE LOCATIONS
	
Q13. AWS Acceptable Use Policy
	• https://aws.amazon.com/aup/
	• No Illegal, Harmful, or Offensive Use or Content
	• No Security Violations
	• No Network Abuse
	• No E-Mail or Other Message Abuse	

################################################################
###########################CHAPTER 4############################
################################################################


Q14. IAM: Users & Groups
	• IAM = Identity and Access Management, Global service
	• Root account created by default, shouldn’t be used or shared
	• Users are people within your organization, and can be grouped
	• Groups only contain users, not other groups
	• Users don’t have to belong to a group, and user can belong to multiple groups


Q15. IAM: Permissions
	• Users or Groups can be assigned JSON documents called policies
	• These policies define the permissions of the users
	• In AWS you apply the least privilege principle: don’t give more permissions than a user needs

{
	"Version": "2012-10-17",
	"Statement": [
					{
					"Effect": "Allow",
					"Action": "ec2:Describe*",
					"Resource": "*"
					},
					{
					"Effect": "Allow",
					"Action": "elasticloadbalancing:Describe*",
					"Resource": "*"
					},
					{
					"Effect": "Allow",
					"Action": [
					"cloudwatch:ListMetrics",
					"cloudwatch:GetMetricStatistics",
					"cloudwatch:Describe*"
					],
					"Resource": "*"
					}
					]
		}	



Q16. IAM Policies Structure
	• Consists of
	• Version: policy language version, always include “2012-10-
	17”
	• Id: an identifier for the policy (optional)
	• Statement: one or more individual statements (required)
	• Statements consists of
	• Sid: an identifier for the statement (optional)
	• Effect: whether the statement allows or denies access
	(Allow, Deny)
	• Principal: account/user/role to which this policy applied to
	• Action: list of actions this policy allows or denies
	• Resource: list of resources to which the actions applied to
	• Condition: conditions for when this policy is in effect
	(optional)


Q17. IAM – Password Policy
	• Strong passwords = higher security for your account
	• In AWS, you can setup a password policy:
	• Set a minimum password length
	• Require specific character types:
	• including uppercase letters
	• lowercase letters
	• numbers
	• non-alphanumeric characters
	• Allow all IAM users to change their own passwords
	• Require users to change their password after some time (password expiration)
	• Prevent password re-use

Q18. Multi Factor Authentication - MFA
	• Users have access to your account and can possibly change
	configurations or delete resources in your AWS account
	• You want to protect your Root Accounts and IAM users
	• MFA = password you know + security device you own
	• Main benefit of MFA:
	if a password is stolen or hacked, the account is not compromised


		MFA devices options in AWS
		Virtual MFA device
		Google Authenticator
		(phone only)
		Authy
		(multi-device)
		Universal 2nd Factor (U2F) Security Key
		YubiKey by Yubico (3rd party)
		Support for multiple tokens on a single device. Support for multiple root and IAM users
		using a single security key

		MFA devices options in AWS
		Hardware Key Fob MFA Device
		Provided by Gemalto (3rd party)
		Hardware Key Fob MFA Device for
		AWS GovCloud (US)
		Provided by SurePassID (3rd party)



Q19. How can users access AWS ?
	• To access AWS, you have three options:
		• AWS Management Console (protected by password + MFA)
		• AWS Command Line Interface (CLI): protected by access keys
		• AWS Software Developer Kit (SDK) - for code: protected by access keys
	• Access Keys are generated through the AWS Console
	• Users manage their own access keys
	• Access Keys are secret, just like a password. Don’t share them
	• Access Key ID ~= username
	• Secret Access Key ~= password

Q20. What’s the AWS CLI?
	• A tool that enables you to interact with AWS services using commands in 	your command-line shell
	• Direct access to the public APIs of AWS services
	• You can develop scripts to manage your resources
	• It’s open-source https://github.com/aws/aws-cli
	• Alternative to using AWS Management Console

Q21. What’s the AWS SDK?
	• AWS Software Development Kit (AWS SDK)
	• Language-specific APIs (set of libraries)
	• Enables you to access and manage AWS services programmatically
	• Embedded within your application
	• Supports
		• SDKs (JavaScript, Python, PHP, .NET, Ruby, Java, Go, Node.js,C++)
		• Mobile SDKs (Android, iOS, …)
		• IoT Device SDKs (Embedded C, Arduino, …)
	• Example: AWS CLI is built on AWS SDK for Python

Q22. IAM Roles for Services
	• Some AWS service will need to perform actions on your behalf
	• To do so, we will assign permissions to AWS services with IAM Roles
	• Common roles:
		• EC2 Instance Roles
		• Lambda Function Roles
		• Roles for CloudFormation

Q23. IAM Security Tools
	• IAM Credentials Report (account-level)
		• a report that lists all your account's users and the status of their various credentials
	• IAM Access Advisor (user-level)
		• Access advisor shows the service permissions granted to a user and when those services were last accessed.
		• You can use this information to revise your policies.

Q24. IAM Guidelines & Best Practices
	• Don’t use the root account except for AWS account setup
	• One physical user = One AWS user
	• Assign users to groups and assign permissions to groups
	• Create a strong password policy
	• Use and enforce the use of Multi Factor Authentication (MFA)
	• Create and use Roles for giving permissions to AWS services
	• Use Access Keys for Programmatic Access (CLI / SDK)
	• Audit permissions of your account using IAM Credentials Report & IAM Access Advisor
	• Never share IAM users & Access Keys		

Q25. Shared Responsibility Model 
	IAM
		• Infrastructure (global network security)
		• Configuration and	vulnerability analysis
		• Compliance validation
	You
		• Users, Groups, Roles, Policies management and monitoring
		• Enable MFA on all accounts
		• Rotate all your keys often
		• Use IAM tools to apply appropriate permissions
		• Analyze access patterns & review permissions	

Q26. IAM Section – Summary
	• Users: mapped to a physical user, has a password for AWS Console
	• Groups: contains users only
	• Policies: JSON document that outlines permissions for users or groups
	• Roles: for EC2 instances or AWS services
	• Security: MFA + Password Policy
	• AWS CLI: manage your AWS services using the command-line8
	• AWS SDK: manage your AWS services using a programming language
	• Access Keys: access AWS using the CLI or SDK
	• Audit: IAM Credential Reports & IAM Access Advisor	

################################################################
###########################CHAPTER 5############################
################################################################

Q27. Amazon EC2
	• EC2 is one of the most popular of AWS’ offering
	• EC2 = Elastic Compute Cloud = Infrastructure as a Service
	• It mainly consists in the capability of :
	• Renting virtual machines (EC2)
	• Storing data on virtual drives (EBS)
	• Distributing load across machines (ELB)
	• Scaling the services using an auto-scaling group (ASG)
	• Knowing EC2 is fundamental to understand how the Cloud works

Q28. EC2 sizing & configuration options
	• Operating System (OS): Linux, Windows or Mac OS
	• How much compute power & cores (CPU)
	• How much random-access memory (RAM)
	• How much storage space:
	• Network-attached (EBS & EFS)
	• hardware (EC2 Instance Store)
	• Network card: speed of the card, Public IP address
	• Firewall rules: security group
	• Bootstrap script (configure at first launch): EC2 User Data


Q29. EC2 User Data
	• It is possible to bootstrap our instances using an EC2 User data script.
	• bootstrapping means launching commands when a machine starts
	• That script is only run once at the instance first start
	• EC2 user data is used to automate boot tasks such as:
	• Installing updates
	• Installing software
	• Downloading common files from the internet
	• Anything you can think of
	• The EC2 User Data Script runs with the root user


Q30. EC2 Instance Types - Overview
	• You can use different types of EC2 instances that are optimised for
	different use cases (https://aws.amazon.com/ec2/instance-types/)
	• AWS has the following naming convention:
	m5.2xlarge
	• m: instance class
	• 5: generation (AWS improves them over time)
	• 2xlarge: size within the instance class

Q31. t2.micro is part of the AWS free tier (up to 750 hours per month)
	Great

Q32. Introduction to Security Groups
	• Security Groups are the fundamental of network security in AWS
	• They control how traffic is allowed into or out of our EC2 Instances.
	• Security groups only contain rules
	• Security groups rules can reference by IP or by security group	

Q33. Security Groups
	Deeper Dive
	• Security groups are acting as a “firewall” on EC2 instances
	• They regulate:
	• Access to Ports
	• Authorised IP ranges – IPv4 and IPv6
	• Control of inbound network (from other to the instance)
	• Control of outbound network (from the instance to other)

Q34. Security Groups
	Good to know
	• Can be attached to multiple instances
	• Locked down to a region / VPC combination
	• Does live “outside” the EC2 – if traffic is blocked the EC2 instance won’t see it
	• It’s good to maintain one separate security group for SSH access
	• If your application is not accessible (time out), then it’s a security group issue
	• If your application gives a “connection refused“ error, then it’s an application
	error or it’s not launched
	• All inbound traffic is blocked by default
	• All outbound traffic is authorised by default

Q35. Classic Ports to know
	• 22 = SSH (Secure Shell) - log into a Linux instance
	• 21 = FTP (File Transfer Protocol) – upload files into a file share
	• 22 = SFTP (Secure File Transfer Protocol) – upload files using SSH
	• 80 = HTTP – access unsecured websites
	• 443 = HTTPS – access secured websites
	• 3389 = RDP (Remote Desktop Protocol) – log into a Windows instance

Q36. EC2 Instances Purchasing Options
	• On-Demand Instances – short workload, predictable pricing, pay by second
	• Reserved (1 & 3 years)
	• Reserved Instances – long workloads
	• Convertible Reserved Instances – long workloads with flexible instances
	• Savings Plans (1 & 3 years) –commitment to an amount of usage, long workload
	• Spot Instances – short workloads, cheap, can lose instances (less reliable)
	• Dedicated Hosts – book an entire physical server, control instance placement
	• Dedicated Instances – no other customers will share your hardware
	• Capacity Reservations – reserve capacity in a specific AZ for any duration

Q37. EC2 On Demand
	• Pay for what you use:
	• Linux or Windows - billing per second, after the first minute
	• All other operating systems - billing per hour
	• Has the highest cost but no upfront payment
	• No long-term commitment
	• Recommended for short-term and un-interrupted workloads, where
	you can't predict how the application will behave

Q38. EC2 Reserved Instances
	• Up to 72% discount compared to On-demand
	• You reserve a specific instance attributes (Instance Type, Region, Tenancy, OS)
	• Reservation Period – 1 year (+discount) or 3 years (+++discount)
	• Payment Options – No Upfront (+), Partial Upfront (++), All Upfront (+++)
	• Reserved Instance’s Scope – Regional or Zonal (reserve capacity in an AZ)
	• Recommended for steady-state usage applications (think database)
	• You can buy and sell in the Reserved Instance Marketplace
	• Convertible Reserved Instance
	• Can change the EC2 instance type, instance family, OS, scope and tenancy
	• Up to 66% discount Note: the % discounts are different from the video as AWS
	change them over time – the exact numbers are not needed
	for the exam. This is just for illustrative purposes J



Q39. EC2 Savings Plans
	• Get a discount based on long-term usage (up to 72% - same as RIs)
	• Commit to a certain type of usage ($10/hour for 1 or 3 years)
	• Usage beyond EC2 Savings Plans is billed at the On-Demand price
	• Locked to a specific instance family & AWS region (e.g., M5 in us-east-1)
	• Flexible across:
	• Instance Size (e.g., m5.xlarge, m5.2xlarge)
	• OS (e.g., Linux, Windows)
	• Tenancy (Host, Dedicated, Default)

Q40. EC2 Spot Instances
	• Can get a discount of up to 90% compared to On-demand
	• Instances that you can “lose” at any point of time if your max price is less than the
	current spot price
	• The MOST cost-efficient instances in AWS
	• Useful for workloads that are resilient to failure
	• Batch jobs
	• Data analysis
	• Image processing
	• Any distributed workloads
	• Workloads with a flexible start and end time
	• Not suitable for critical jobs or databases

Q41. EC2 Dedicated Hosts
	• A physical server with EC2 instance capacity fully dedicated to your use
	• Allows you address compliance requirements and use your existing serverbound
	software licenses (per-socket, per-core, pe—VM software licenses)
	• Purchasing Options:
	• On-demand – pay per second for active Dedicated Host
	• Reserved - 1 or 3 years (No Upfront, Partial Upfront, All Upfront)
	• The most expensive option
	• Useful for software that have complicated licensing model (BYOL – Bring Your
	Own License)
	• Or for companies that have strong regulatory or compliance needs

Q42. EC2 Dedicated Instances
	• Instances run on hardware that’s
	dedicated to you
	• May share hardware with other
	instances in same account
	• No control over instance placement
	(can move hardware after Stop / Start)

Q43. EC2 Capacity Reservations
	• Reserve On-Demand instances capacity in a specific AZ for any
	duration
	• You always have access to EC2 capacity when you need it
	• No time commitment (create/cancel anytime), no billing discounts
	• Combine with Regional Reserved Instances and Savings Plans to benefit
	from billing discounts
	• You’re charged at On-Demand rate whether you run instances or not
	• Suitable for short-term, uninterrupted workloads that needs to be in a
	specific AZ

Q44. Which purchasing option is right for me?
	• On demand: coming and staying in resort
	whenever we like, we pay the full price
	• Reserved: like planning ahead and if we plan to
	stay for a long time, we may get a good discount.
	• Savings Plans: pay a certain amount per hour for
	certain period and stay in any room type (e.g.,
	King, Suite, Sea View, …)
	• Spot instances: the hotel allows people to bid for
	the empty rooms and the highest bidder keeps the
	rooms. You can get kicked out at any time
	• Dedicated Hosts: We book an entire building of
	the resort
	• Capacity Reservations: you book a room for a
	period with full price even you don’t stay in it

Q45. Shared Responsibility Model for EC2
	aws
	• Infrastructure (global
	network security)
	• Isolation on physical hosts
	• Replacing faulty hardware
	• Compliance validation
	user
	• Security Groups rules
	• Operating-system patches and
	updates
	• Software and utilities installed
	on the EC2 instance
	• IAM Roles assigned to EC2 &
	IAM user access management
	• Data security on your instance


Q46. EC2 Section – Summary
	• EC2 Instance: AMI (OS) + Instance Size (CPU + RAM) + Storage +
	security groups + EC2 User Data
	• Security Groups: Firewall attached to the EC2 instance
	• EC2 User Data: Script launched at the first start of an instance
	• SSH: start a terminal into our EC2 Instances (port 22)
	• EC2 Instance Role: link to IAM roles
	• Purchasing Options: On-Demand, Spot, Reserved (Standard +
	Convertible + Scheduled), Dedicated Host, Dedicated Instance

################################################################
#########CHAPTER 6 - EC2 Instance Storage Section ##############
################################################################

Q47. What’s an EBS Volume?
	• An EBS (Elastic Block Store) Volume is a network drive you can attach to your instances while they run
	• It allows your instances to persist data, even after their termination
	• They can only be mounted to one instance at a time (at the CCP level)
	• They are bound to a specific availability zone
	• Analogy: Think of them as a “network USB stick”
	• Free tier: 30 GB of free EBS storage of type General Purpose (SSD) or Magnetic per month

Q48. EBS Volume
	• It’s a network drive (i.e. not a physical drive)
	• It uses the network to communicate the instance, which means there might be a bit of
	latency
	• It can be detached from an EC2 instance and attached to another one quickly
	• It’s locked to an Availability Zone (AZ)
	• An EBS Volume in us-east-1a cannot be attached to us-east-1b
	• To move a volume across, you first need to snapshot it
	• Have a provisioned capacity (size in GBs, and IOPS)
	• You get billed for all the provisioned capacity
	• You can increase the capacity of the drive over time

Q49. EBS – Delete on Termination attribute
	• Controls the EBS behaviour when an EC2 instance terminates
	• By default, the root EBS volume is deleted (attribute enabled)
	• By default, any other attached EBS volume is not deleted (attribute disabled)
	• This can be controlled by the AWS console / AWS CLI
	• Use case: preserve root volume when instance is terminated

Q50. EBS Snapshots
	• Make a backup (snapshot) of your EBS volume at a point in time
	• Not necessary to detach volume to do snapshot, but recommended
	• Can copy snapshots across AZ or Region


Q51. EBS Snapshots Features
	• EBS Snapshot Archive
	• Move a Snapshot to an ”archive tier” that is
	75% cheaper
	• Takes within 24 to 72 hours for restoring
	the archive
	• Recycle Bin for EBS Snapshots
	• Setup rules to retain deleted snapshots so
	you can recover them after an accidental
	deletion
	• Specify retention (from 1 day to 1 year)

Q52. AMI Overview
	• AMI = Amazon Machine Image
	• AMI are a customization of an EC2 instance
	• You add your own software, configuration, operating system, monitoring…
	• Faster boot / configuration time because all your software is pre-packaged
	• AMI are built for a specific region (and can be copied across regions)
	• You can launch EC2 instances from:
	• A Public AMI: AWS provided
	• Your own AMI: you make and maintain them yourself
	• An AWS Marketplace AMI: an AMI someone else made (and potentially sells)

Q53. AMI Process (from an EC2 instance)
	• Start an EC2 instance and customize it
	• Stop the instance (for data integrity)
	• Build an AMI – this will also create EBS snapshots
	• Launch instances from other AMIs
	US-EAST-1A US-EAST-1B
	Custom AMI
	Create AMI
	Launch
	from AMI


Q54. EC2 Image Builder
	• Used to automate the creation of Virtual Machines or container images
	• => Automate the creation, maintain, validate and test EC2 AMIs
	• Can be run on a schedule (weekly, whenever packages are updated, etc…)
	• Free service (only pay for the underlying resources)
	EC2 Image Builder Builder EC2 Instance
	create
	Build Components applied
	(customize software on instance)
	New AMI
	create
	Test EC2 Instance
	Test suite is run
	(is the AMI working, secure?)
	AMI is distributed
	(can be multiple regions


Q55. EC2 Instance Store
	• EBS volumes are network drives with good but “limited” performance
	• If you need a high-performance hardware disk, use EC2 Instance
	Store
	• Better I/O performance
	• EC2 Instance Store lose their storage if they’re stopped (ephemeral)
	• Good for buffer / cache / scratch data / temporary content
	• Risk of data loss if hardware fails
	• Backups and Replication are your responsibility


Q56. EFS – Elastic File System
	• Managed NFS (network file system) that can be mounted on 100s of EC2
	• EFS works with Linux EC2 instances in multi-AZ
	• Highly available, scalable, expensive (3x gp2), pay per use, no capacity planning
	us-east-1a
	EC2 Instances
	us-east-1b
	EC2 Instances
	us-east-1c
	EC2 Instances
	Security Group
	EFS

Q57. EFS Infrequent Access (EFS-IA)
	• Storage class that is cost-optimized for files not
	accessed every day
	• Up to 92% lower cost compared to EFS Standard
	• EFS will automatically move your files to EFS-IA
	based on the last time they were accessed
	• Enable EFS-IA with a Lifecycle Policy
	• Example: move files that are not accessed for 60
	days to EFS-IA
	• Transparent to the applications accessing EFS

Q58. Shared Responsibility Model for EC2 Storage
	• Infrastructure
	• Replication for data for EBS
	volumes & EFS drives
	• Replacing faulty hardware
	• Ensuring their employees
	cannot access your data
	• Setting up backup / snapshot
	procedures
	• Setting up data encryption
	• Responsibility of any data on
	the drives
	• Understanding the risk of
	using EC2 Instance Store

Q59. Amazon FSx – Overview
	• Launch 3rd party high-performance file systems on AWS
	• Fully managed service
	FSx for Lustre FSx for
	Windows File
	Server
	FSx for
	NetApp ONTAP


Q60. Amazon FSx for Windows File Server
	• A fully managed, highly reliable, and
	scalable Windows native shared
	file system
	• Built on Windows File Server
	• Supports SMB protocol &
	Windows NTFS
	• Integrated with Microsoft Active
	Directory
	• Can be accessed from AWS or
	your on-premise infrastructure
	Region
	Availability Zone 1 Availability Zone 2
	FSx for Windows
	File Server
	FSx for Windows
	File Server
	Corporate data center
	\\fs-0123456789abcdef0.example.com\share
	EC2 instance
	Windows

Q61. Amazon FSx for Lustre
	• A fully managed, high-performance, scalable file storage for High Performance
	Computing (HPC)
	• The name Lustre is derived from “Linux” and “cluster”
	• Machine Learning, Analytics, Video Processing, Financial Modeling, …
	• Scales up to 100s GB/s, millions of IOPS, sub-ms latencies
	Region Corporate data center
	Compute instances
	Amazon FSx for Lustre
	Amazon S3
	link
	Server
	access your data
	access your data

Q62. EC2 Instance Storage - Summary
	• EBS volumes:
	• network drives attached to one EC2 instance at a time
	• Mapped to an Availability Zones
	• Can use EBS Snapshots for backups / transferring EBS volumes across AZ
	• AMI: create ready-to-use EC2 instances with our customizations
	• EC2 Image Builder: automatically build, test and distribute AMIs
	• EC2 Instance Store:
	• High performance hardware disk attached to our EC2 instance
	• Lost if our instance is stopped / terminated
	• EFS: network file system, can be attached to 100s of instances in a region
	• EFS-IA: cost-optimized storage class for infrequent accessed files
	• FSx for Windows: Network File System for Windows servers
	• FSx for Lustre: High Performance Computing Linux file system


########################################################
#########Elastic Load Balancing & Auto##################
Scaling Groups Section##################################
########################################################

Q63. Scalability & High Availability
	• Scalability means that an application / system can handle greater loads
	by adapting.
	• There are two kinds of scalability:
	• Vertical Scalability
	• Horizontal Scalability (= elasticity)
	• Scalability is linked but different to High Availability
	• Let’s deep dive into the distinction, using a call center as an example

Q64. Vertical Scalability
	• Vertical Scalability means increasing the size
	of the instance
	• For example, your application runs on a
	t2.micro
	• Scaling that application vertically means
	running it on a t2.large
	• Vertical scalability is very common for non
	distributed systems, such as a database.
	• There’s usually a limit to how much you can
	vertically scale (hardware limit)
	junior operator senior operator


Q65. Horizontal Scalability
	• Horizontal Scalability means increasing the
	number of instances / systems for your
	application
	• Horizontal scaling implies distributed systems.
	• This is very common for web applications /
	modern applications
	• It’s easy to horizontally scale thanks the cloud
	offerings such as Amazon EC2
	operator

Q66. High Availability
	• High Availability usually goes hand
	in hand with horizontal scaling
	• High availability means running
	your application / system in at
	least 2 Availability Zones
	• The goal of high availability is to
	survive a data center loss
	(disaster)

Q67. High Availability & Scalability For EC2
	• Vertical Scaling: Increase instance size (= scale up / down)
	• From: t2.nano - 0.5G of RAM, 1 vCPU
	• To: u-12tb1.metal – 12.3 TB of RAM, 448 vCPUs
	• Horizontal Scaling: Increase number of instances (= scale out / in)
	• Auto Scaling Group
	• Load Balancer
	• High Availability: Run instances for the same application across multi AZ
	• Auto Scaling Group multi AZ
	• Load Balancer multi AZ

Q68. Scalability vs Elasticity (vs Agility)
	• Scalability: ability to accommodate a larger load by making the
	hardware stronger (scale up), or by adding nodes (scale out)
	• Elasticity: once a system is scalable, elasticity means that there will be
	some “auto-scaling” so that the system can scale based on the load. This
	is “cloud-friendly”: pay-per-use, match demand, optimize costs
	• Agility: (not related to scalability - distractor) new IT resources are only
	a click away, which means that you reduce the time to make those
	resources available to your developers from weeks to just minutes

Q69. What is load balancing?
	• Load balancers are servers that forward internet traffic to multiple
	servers (EC2 Instances) downstream.
	Load Balancer
	User 1
	User 2
	User 3



Q70. Why use a load balancer?
• Spread load across multiple downstream instances
• Expose a single point of access (DNS) to your application
• Seamlessly handle failures of downstream instances
• Do regular health checks to your instances
• Provide SSL termination (HTTPS) for your websites
• High availability across zones


Q71. Why use an Elastic Load Balancer?
	• An ELB (Elastic Load Balancer) is a managed load balancer
	• AWS guarantees that it will be working
	• AWS takes care of upgrades, maintenance, high availability
	• AWS provides only a few configuration knobs
	• It costs less to setup your own load balancer but it will be a lot more
	effort on your end (maintenance, integrations)
	• 4 kinds of load balancers offered by AWS:
	• Application Load Balancer (HTTP / HTTPS only) – Layer 7
	• Network Load Balancer (ultra-high performance, allows for TCP) – Layer 4
	• Gateway Load Balancer – Layer 3
	• Classic Load Balancer (retired in 2023) – Layer 4 & 7


Q72. Network Load Balancer
	• TCP / UDP protocols
	(Layer 4)
	• High Performance: millions of
	request per seconds
	• Static IP through Elastic IP
	Application Load
	Balancer
	• HTTP / HTTPS / gRPC
	protocols (Layer 7)
	• HTTP Routing features
	• Static DNS (URL)
	Gateway Load Balancer
	• GENEVE Protocol on
	IP Packets (Layer 3)
	• Route Traffic to Firewalls that
	you manage on EC2 Instances
	• Intrusion detection

Q73. What’s an Auto Scaling Group?
	• In real-life, the load on your websites and application can change
	• In the cloud, you can create and get rid of servers very quickly
	• The goal of an Auto Scaling Group (ASG) is to:
	• Scale out (add EC2 instances) to match an increased load
	• Scale in (remove EC2 instances) to match a decreased load
	• Ensure we have a minimum and a maximum number of machines running
	• Automatically register new instances to a load balancer
	• Replace unhealthy instances
	• Cost Savings: only run at an optimal capacity (principle of the cloud)


Q74. Auto Scaling Groups – Scaling Strategies
	• Manual Scaling: Update the size of an ASG manually
	• Dynamic Scaling: Respond to changing demand
	• Simple / Step Scaling
	• When a CloudWatch alarm is triggered (example CPU > 70%), then add 2 units
	• When a CloudWatch alarm is triggered (example CPU < 30%), then remove 1
	• Target Tracking Scaling
	• Example: I want the average ASG CPU to stay at around 40%
	• Scheduled Scaling
	• Anticipate a scaling based on known usage patterns
	• Example: increase the min. capacity to 10 at 5 pm on Fridays

Q75. Auto Scaling Groups – Scaling Strategies
	• Predictive Scaling
	• Uses Machine Learning
	to predict future traffic
	ahead of time
	• Automatically
	provisions the right
	number of EC2
	instances in advance
	• Useful when your load
	has predictable timebased
	patterns

Q76. ELB & ASG – Summary
	• High Availability vs Scalability (vertical and horizontal) vs Elasticity vs
	Agility in the Cloud
	• Elastic Load Balancers (ELB)
	• Distribute traffic across backend EC2 instances, can be Multi-AZ
	• Supports health checks
	• 4 types: Classic (old), Application (HTTP – L7), Network (TCP – L4), Gateway (L3)
	• Auto Scaling Groups (ASG)
	• Implement Elasticity for your application, across multiple AZ
	• Scale EC2 instances based on the demand on your system, replace unhealthy
	• Integrated with the ELB

############################################################################################
			#######################Amazon S3 Section########################
############################################################################################




Q77. Section introduction
	• Amazon S3 is one of the main building blocks of AWS
	• It’s advertised as ”infinitely scaling” storage
	• Many websites use Amazon S3 as a backbone
	• Many AWS services use Amazon S3 as an integration as well
	• We’ll have a step-by-step approach to S3

Q78. Amazon S3 Use cases
	• Backup and storage
	• Disaster Recovery
	• Archive
	• Hybrid Cloud storage
	• Application hosting
	• Media hosting
	• Data lakes & big data analytics
	• Software delivery
	• Static website
	Nasdaq stores 7 years of
	data into S3 Glacier
	Sysco runs analytics on
	its data and gain business
	insights

Q79. Amazon S3 - Buckets
	• Amazon S3 allows people to store objects (files) in “buckets” (directories)
	• Buckets must have a globally unique name (across all regions all accounts)
	• Buckets are defined at the region level
	• S3 looks like a global service but buckets are created in a region
	• Naming convention
	• No uppercase, No underscore
	• 3-63 characters long
	• Not an IP
	• Must start with lowercase letter or number
	• Must NOT start with the prefix xn--
	• Must NOT end with the suffix -s3alias S3 Bucket


Q80. Amazon S3 - Objects
	• Objects (files) have a Key
	• The key is the FULL path:
	• s3://my-bucket/my_file.txt
	• s3://my-bucket/my_folder1/another_folder/my_file.txt
	• The key is composed of prefix + object name
	• s3://my-bucket/my_folder1/another_folder/my_file.txt
	• There’s no concept of “directories” within buckets
	(although the UI will trick you to think otherwise)
	• Just keys with very long names that contain slashes (“/”)



Q81. Amazon S3 – Objects (cont.)
	• Object values are the content of the body:
	• Max. Object Size is 5TB (5000GB)
	• If uploading more than 5GB, must use “multi-part upload”
	• Metadata (list of text key / value pairs – system or user metadata)
	• Tags (Unicode key / value pair – up to 10) – useful for security / lifecycle
	• Version ID (if versioning is enabled)


Q82. Amazon S3 – Security
	• User-Based
	• IAM Policies – which API calls should be allowed for a specific user from IAM
	• Resource-Based
	• Bucket Policies – bucket wide rules from the S3 console - allows cross account
	• Object Access Control List (ACL) – finer grain (can be disabled)
	• Bucket Access Control List (ACL) – less common (can be disabled)
	• Note: an IAM principal can access an S3 object if
	• The user IAM permissions ALLOW it OR the resource policy ALLOWS it
	• AND there’s no explicit DENY
	• Encryption: encrypt objects in Amazon S3 using encryption keys


Q83. S3 Bucket Policies
	• JSON based policies
	• Resources: buckets and objects
	• Effect: Allow / Deny
	• Actions: Set of API to Allow or Deny
	• Principal: The account or user to apply the
	policy to
	• Use S3 bucket for policy to:
	• Grant public access to the bucket
	• Force objects to be encrypted at upload
	• Grant access to another account (Cross
	Account)

Q84. Amazon S3 – Static Website Hosting
	• S3 can host static websites and have them accessible on
	the Internet
	• The website URL will be (depending on the region)
	• http://bucket-name.s3-website-aws-region.amazonaws.com
	OR
	• http://bucket-name.s3-website.aws-region.amazonaws.com
	• If you get a 403 Forbidden error, make sure the bucket
	policy allows public reads!
	S3 Bucket
	(demo-bucket

Q85. Amazon S3 - Versioning
	• You can version your files in Amazon S3
	• It is enabled at the bucket level
	• Same key overwrite will change the “version”: 1, 2, 3….
	• It is best practice to version your buckets
	• Protect against unintended deletes (ability to restore a version)
	• Easy roll back to previous version
	• Notes:
	• Any file that is not versioned prior to enabling versioning will
	have version “null”
	• Suspending versioning does not delete the previous versions
	S3 Bucket
	(my-bucket)
	s3://my-bucket/my-file.docx


Q86. Amazon S3 – Replication (CRR & SRR)
	• Must enable Versioning in source and destination buckets
	• Cross-Region Replication (CRR)
	• Same-Region Replication (SRR)
	• Buckets can be in different AWS accounts
	• Copying is asynchronous
	• Must give proper IAM permissions to S3
	• Use cases:
	• CRR – compliance, lower latency access, replication across
	accounts
	• SRR – log aggregation, live replication between production and test
	accounts
	S3 Bucket
	(eu-west-1)
	S3 Bucket
	(us-east-2)
	asynchronous
	replication

Q87. S3 Storage Classes
	• Amazon S3 Standard - General Purpose
	• Amazon S3 Standard-Infrequent Access (IA)
	• Amazon S3 One Zone-Infrequent Access
	• Amazon S3 Glacier Instant Retrieval
	• Amazon S3 Glacier Flexible Retrieval
	• Amazon S3 Glacier Deep Archive
	• Amazon S3 Intelligent Tiering
	• Can move between classes manually or using S3 Lifecycle configurations

Q88. S3 Durability and Availability
	• Durability:
	• High durability (99.999999999%, 11 9’s) of objects across multiple AZ
	• If you store 10,000,000 objects with Amazon S3, you can on average expect to
	incur a loss of a single object once every 10,000 years
	• Same for all storage classes
	• Availability:
	• Measures how readily available a service is
	• Varies depending on storage class
	• Example: S3 standard has 99.99% availability = not available 53 minutes a year

Q89. S3 Standard – General Purpose
	• 99.99% Availability
	• Used for frequently accessed data
	• Low latency and high throughput
	• Sustain 2 concurrent facility failures
	• Use Cases: Big Data analytics, mobile & gaming applications, content
	distribution…

Q90. S3 Storage Classes – Infrequent Access
	• For data that is less frequently accessed, but requires rapid access when needed
	• Lower cost than S3 Standard
	• Amazon S3 Standard-Infrequent Access (S3 Standard-IA)
	• 99.9% Availability
	• Use cases: Disaster Recovery, backups
	• Amazon S3 One Zone-Infrequent Access (S3 One Zone-IA)
	• High durability (99.999999999%) in a single AZ; data lost when AZ is destroyed
	• 99.5% Availability
	• Use Cases: Storing secondary backup copies of on-premise data, or data you can recreate

Q91. Amazon S3 Glacier Storage Classes
	• Low-cost object storage meant for archiving / backup
	• Pricing: price for storage + object retrieval cost
	• Amazon S3 Glacier Instant Retrieval
	• Millisecond retrieval, great for data accessed once a quarter
	• Minimum storage duration of 90 days
	• Amazon S3 Glacier Flexible Retrieval (formerly Amazon S3 Glacier):
	• Expedited (1 to 5 minutes), Standard (3 to 5 hours), Bulk (5 to 12 hours) – free
	• Minimum storage duration of 90 days
	• Amazon S3 Glacier Deep Archive – for long term storage:
	• Standard (12 hours), Bulk (48 hours)
	• Minimum storage duration of 180 days

Q92. S3 Intelligent-Tiering
	• Small monthly monitoring and auto-tiering fee
	• Moves objects automatically between Access Tiers based on usage
	• There are no retrieval charges in S3 Intelligent-Tiering
	• Frequent Access tier (automatic): default tier
	• Infrequent Access tier (automatic): objects not accessed for 30 days
	• Archive Instant Access tier (automatic): objects not accessed for 90 days
	• Archive Access tier (optional): configurable from 90 days to 700+ days
	• Deep Archive Access tier (optional): config. from 180 days to 700+ days


Q93. Shared Responsibility Model for S3
	• Infrastructure (global security,
	durability, availability, sustain
	concurrent loss of data in
	two facilities)
	• Configuration and
	vulnerability analysis
	• Compliance validation
	• S3 Versioning
	• S3 Bucket Policies
	• S3 Replication Setup
	• Logging and Monitoring
	• S3 Storage Classes
	• Data encryption at rest and in
	transit


Q94. AWS Snow Family
	• Highly-secure, portable devices to collect and process data at the
	edge, and migrate data into and out of AWS
	• Data migration:
	• Edge computing:
	Snowcone Snowball Edge Snowmobile
	Snowcone Snowball Edge

Q95. Snowball Edge (for data transfers)
	• Physical data transport solution: move TBs or PBs of data in or out
	of AWS
	• Alternative to moving data over the network (and paying network
	fees)
	• Pay per data transfer job
	• Provide block storage and Amazon S3-compatible object storage
	• Snowball Edge Storage Optimized
	• 80 TB of HDD capacity for block volume and S3 compatible object
	storage
	• Snowball Edge Compute Optimized
	• 42 TB of HDD or 28TB NVMe capacity for block volume and S3
	compatible object storage
	• Use cases: large data cloud migrations, DC decommission, disaster
	recovery


Q96. AWS Snowcone & Snowcone SSD
	• Small, portable computing, anywhere, rugged &
	secure, withstands harsh environments
	• Light (4.5 pounds, 2.1 kg)
	• Device used for edge computing, storage, and data
	transfer
	• Snowcone – 8 TB of HDD Storage
	• Snowcone SSD – 14 TB of SSD Storage
	• Use Snowcone where Snowball does not fit (spaceconstrained
	environment)
	• Must provide your own battery / cables
	• Can be sent back to AWS offline, or connect it to
	internet and use AWS DataSync to send data


Q97. AWS Snowmobile
	• Transfer exabytes of data (1 EB = 1,000 PB = 1,000,000 TBs)
	• Each Snowmobile has 100 PB of capacity (use multiple in parallel)
	• High security: temperature controlled, GPS, 24/7 video surveillance
	• Better than Snowball if you transfer more than 10 PB

Q98. Snow Family – Usage Process
	1. Request Snowball devices from the AWS console for delivery
	2. Install the snowball client / AWS OpsHub on your servers
	3. Connect the snowball to your servers and copy files using the client
	4. Ship back the device when you’re done (goes to the right AWS
	facility)
	5. Data will be loaded into an S3 bucket
	6. Snowball is completely wiped


Q99. What is Edge Computing?
	• Process data while it’s being created on an edge location
	• A truck on the road, a ship on the sea, a mining station underground...
	• These locations may have
	• Limited / no internet access
	• Limited / no easy access to computing power
	• We setup a Snowball Edge / Snowcone device to do edge computing
	• Use cases of Edge Computing:
	• Preprocess data
	• Machine learning at the edge
	• Transcoding media streams
	• Eventually (if need be) we can ship back the device to AWS (for transferring data for example

Q100. Snow Family – Edge Computing
	• Snowcone & Snowcone SSD (smaller)
	• 2 CPUs, 4 GB of memory, wired or wireless access
	• USB-C power using a cord or the optional battery
	• Snowball Edge – Compute Optimized
	• 104 vCPUs, 416 GiB of RAM
	• Optional GPU (useful for video processing or machine learning)
	• 28TB NVMe or 42TB HDD usable storage
	• Storage Clustering available (up to 16 nodes)
	• Snowball Edge – Storage Optimized
	• Up to 40 vCPUs, 80 GiB of RAM, 80 TB storage
	• All: Can run EC2 Instances & AWS Lambda functions (using AWS IoT Greengrass)
	• Long-term deployment options: 1 and 3 years discounted pricing

Q101. AWS OpsHub
	• Historically, to use Snow Family devices, you
	needed a CLI (Command Line Interface tool)
	• Today, you can use AWS OpsHub (a software
	you install on your computer / laptop) to
	manage your Snow Family Device
	• Unlocking and configuring single or clustered devices
	• Transferring files
	• Launching and managing instances running on Snow
	Family Devices
	• Monitor device metrics (storage capacity, active
	instances on your device)
	• Launch compatible AWS services on your devices
	(ex: Amazon EC2 instances, AWS DataSync,
	Network File System (NFS))
	https://aws.amazon.com/blogs/aws/aws-snowball-edge-update

Q102. Snowball Edge Pricing
	• You pay for device usage and data transfer out of AWS
	• Data transfer IN to Amazon S3 is $0.00 per GB
	• On-Demand
	• Includes a one-time service fee per job, which includes:
	• 10 days of usage for Snowball Edge Storage Optimized 80TB
	• 15 days of usage for Snowball Edge Storage Optimized 210TB
	• Shipping days are NOT counted towards the included 10 or 15 days
	• Pay per day for any additional days
	• Committed Upfront
	• Pay in advance for monthly, 1-year, and 3-years of usage (Edge Computing)
	• Up to 62% discounted pricing

Q103. Hybrid Cloud for Storage
	• AWS is pushing for ”hybrid cloud”
	• Part of your infrastructure is on-premises
	• Part of your infrastructure is on the cloud
	• This can be due to
	• Long cloud migrations
	• Security requirements
	• Compliance requirements
	• IT strategy
	• S3 is a proprietary storage technology (unlike EFS / NFS), so how do you
	expose the S3 data on-premise?
	• AWS Storage Gateway!

Q104. AWS Storage Gateway
	• Bridge between on-premise data and cloud
	data in S3
	• Hybrid storage service to allow onpremises
	to seamlessly use the AWS
	Cloud
	• Use cases: disaster recovery, backup &
	restore, tiered storage
	• Types of Storage Gateway:
	• File Gateway
	• Volume Gateway
	• Tape Gateway
	• No need to know the types at the exam
	Amazon EBS S3 Glacier

Q105. Amazon S3 – Summary
	• Buckets vs Objects: global unique name, tied to a region
	• S3 security: IAM policy, S3 Bucket Policy (public access), S3 Encryption
	• S3 Websites: host a static website on Amazon S3
	• S3 Versioning: multiple versions for files, prevent accidental deletes
	• S3 Replication: same-region or cross-region, must enable versioning
	• S3 Storage Classes: Standard, IA, 1Z-IA, Intelligent, Glacier (Instant, Flexible, Deep)
	• Snow Family: import data onto S3 through a physical device, edge computing
	• OpsHub: desktop application to manage Snow Family devices
	• Storage Gateway: hybrid solution to extend on-premises storage to S3

	
############################################################################################
			#######################Other Compute Section########################
############################################################################################
	
Where Docker images are stored?
	• Docker: container technology to run applications
	• Docker images are stored in Docker Repositories
	• Public: Docker Hub https://hub.docker.com/
	• Find base images for many technologies or OS:
	• Ubuntu
	• MySQL
	• NodeJS, Java…
	• Private: Amazon ECR (Elastic Container Registry)

ECS
	• ECS = Elastic Container Service
	• Launch Docker containers on AWS
	• You must provision & maintain the infrastructure (the EC2 instances)
	• AWS takes care of starting / stopping containers
	• Has integrations with the Application Load Balancer	
	• ECS: run Docker containers on EC2 instances
Fargate
	• Launch Docker containers on AWS
	• You do not provision the infrastructure (no EC2 instances to manage) – simpler!
	• Serverless offering
	• AWS just runs containers for you based on the CPU / RAM

ECR
	• Elastic Container Registry
	• Private Docker Registry on AWS
	• This is where you store your Docker images so they can be run by ECS or Fargate
	• ECR: Private Docker Images Repository	
What’s serverless?
	• Initially... Serverless == FaaS (Function as a Service)
	• Serverless was pioneered by AWS Lambda but now also includes anything that’s managed: “databases, messaging, storage, etc.”
	• Serverless does not mean there are no servers… it means you just don’t manage / provision / see them and just deploy code
	EG.	Amazon S3, DynamoDB, Fargate, Lambda

AWS Lambda
	Difference from EC2
		EC2
		• Virtual Servers in the Cloud
		• Limited by RAM and CPU
		• Continuously running
		• Scaling means intervention to add / remove servers
		Lambda
		• Virtual functions – no servers to manage!
		• Limited by time - short executions
		• Run on-demand
		• Scaling is automated!

Benefits of AWS Lambda
	• Integrated with the whole AWS suite of services
	• Event-Driven: functions get invoked by AWS when needed
	• Integrated with many programming languages
	• Easy monitoring through AWS CloudWatch
	• Easy to get more resources per functions (up to 10GB of RAM!)
	• Increasing RAM will also improve CPU and network!
	• Invocation time: up to 15 minutes

AWS Lambda language support
	• many programming languages except (arbitrary) Docker
	• Has Custom Runtime API (community supported, example Rust)
	• Lambda Container Image
	• The container image must implement the Lambda Runtime API, so its very limited images are supported
	• ECS / Fargate is preferred for running arbitrary Docker images

Use cases:
	• Create Thumbnails for images uploaded onto S3
	• Run a Serverless cron job

AWS Lambda Pricing: example
	• Pay per calls:
		• First 1,000,000 requests are free
		• $0.20 per 1 million requests thereafter ($0.0000002 per request)
	• Pay per duration: (in increment of 1 ms)
		• 400,000 GB-seconds of compute time per month for FREE
		• == 400,000 seconds if function is 1GB RAM
		• == 3,200,000 seconds if function is 128 MB RAM
	• It is usually very cheap to run AWS Lambda so it’s very popular
	

API Gateway 
	• expose Lambda functions as HTTP API

Lightsail
	• predictable & low pricing for simple application & DB stacks
	• Great for people with little cloud experience!
	• Can setup notifications and monitoring of your Lightsail resources
	• Use cases:
		• Simple web applications (has templates for LAMP, Nginx, MEAN, Node.js…)
		• Websites (templates for WordPress, Magento, Plesk, Joomla)
		• Dev / Test environment
		• Has high availability but no auto-scaling, limited AWS integrations

Batch
	• run batch jobs on AWS across managed EC2 instances, not serverless
	• Fully managed batch processing at any scale
	• Efficiently run 100,000s of computing batch jobs on AWS
	• A “batch” job is a job with a start and an end (opposed to continuous)
	• Batch will dynamically launch EC2 instances or Spot Instances
	• AWS Batch provisions the right amount of compute / memory
	• You submit or schedule batch jobs and AWS Batch does the rest!
	• Batch jobs are defined as Docker images and run on ECS
	• Helpful for cost optimizations and focusing less on the infrastructure

Batch vs Lambda
	• Lambda:
		• Time limit
		• Limited runtimes
		• Limited temporary disk space
	• Serverless
		• Batch:
		• No time limit
		• Any runtime as long as it’s packaged as a Docker image
		• Rely on EBS / instance store for disk space
		• Relies on EC2 (can be managed by AWS)


############################################################################################
#######################Deploying and Managing Infrastructure at Scale Section########################
############################################################################################

What is CloudFormation
	• CloudFormation is a declarative way of outlining your AWS
	Infrastructure, for any resources (most of them are supported).
	• For example, within a CloudFormation template, you say:
		• I want a security group
		• I want two EC2 instances using this security group
		• I want an S3 bucket
		• I want a load balancer (ELB) in front of these machines
		• Then CloudFormation creates those for you, in the right order, with the exact configuration that you specify
		
Benefits of AWS CloudFormation (1/2)
	• Infrastructure as code
		• No resources are manually created, which is excellent for control
		• Changes to the infrastructure are reviewed through code
	• Cost
		• Each resources within the stack is tagged with an identifier so you can easily see how
		much a stack costs you
		• You can estimate the costs of your resources using the CloudFormation template
		• Savings strategy: In Dev, you could automation deletion of templates at 5 PM and
		recreated at 8 AM, safely		
	• Productivity
		• Ability to destroy and re-create an infrastructure on the cloud on the fly
		• Automated generation of Diagram for your templates!
		• Declarative programming (no need to figure out ordering and orchestration)
	• Don’t re-invent the wheel
		• Leverage existing templates on the web!
		• Leverage the documentation
	• Supports (almost) all AWS resources:
		• Everything we’ll see in this course is supported
		• You can use “custom resources” for resources that are not supported	
AWS Cloud Development Kit (CDK)
	• Define your cloud infrastructure using a familiar language:
		• JavaScript/TypeScript, Python, Java, and .NET		
	• The code is “compiled” into a CloudFormation template (JSON/YAML)
		• You can therefore deploy infrastructure and application runtime code together
		• Great for Docker containers in ECS / EKS		
	• Great for Lambda functions
	
AWS Elastic Beanstalk Overview
	• Elastic Beanstalk is a developer centric view of deploying an application on AWS
	• It uses all the component’s we’ve seen before: EC2, ASG, ELB, RDS, etc…
	• But it’s all in one view that’s easy to make sense of!
	• We still have full control over the configuration
	• Beanstalk = Platform as a Service (PaaS)
	• Beanstalk is free but you pay for the underlying instances	

Elastic Beanstalk
	• Managed service
		• Instance configuration / OS is handled by Beanstalk
		• Deployment strategy is configurable but performed by Elastic Beanstalk
		• Capacity provisioning
		• Load balancing & auto-scaling
		• Application health-monitoring & responsiveness
	• Just the application code is the responsibility of the developer
	• Three architecture models:
		• Single Instance deployment: good for dev
		• LB + ASG: great for production or pre-production web applications
		• ASG only: great for non-web apps in production (workers, etc..)	
		
AWS CodeDeploy
	• We want to deploy our application automatically
	• Works with EC2 Instances
	• Works with On-Premises Servers
	• Hybrid service
	• Servers / Instances must be provisioned and configured ahead of time with the CodeDeploy Agent		

AWS CodeCommit
	• Before pushing the application code to servers, it needs to be stored
	somewhere
	• Developers usually store code in a repository, using the Git technology
	• A famous public offering is GitHub, AWS’ competing product is
	CodeCommit
	• CodeCommit:
		• Source-control service that hosts Git-based repositories
		• Makes it easy to collaborate with others on code
		• The code changes are automatically versioned
	• Benefits:
		• Fully managed
		• Scalable & highly available
		• Private, Secured, Integrated with AWS	

AWS CodeBuild
	• Code building service in the cloud (name is obvious)
	• Compiles source code, run tests, and produces packages that are ready to
	be deployed (by CodeDeploy for example)
	• Benefits:
		• Fully managed, serverless
		• Continuously scalable & highly available
		• Secure
		• Pay-as-you-go pricing – only pay for the build time
		
AWS CodePipeline
	• Orchestrate the different steps to have the code automatically pushed to production
	• Code => Build => Test => Provision => Deploy
	• Basis for CICD (Continuous Integration & Continuous Delivery)
	Benefits:
		• Fully managed, compatible with CodeCommit, CodeBuild, CodeDeploy, Elastic Beanstalk,
	CloudFormation, GitHub, 3rd-party services (GitHub…) & custom plugins…
		• Fast delivery & rapid updates

AWS CodeArtifact
	• Software packages depend on each other to be built (also called code
	dependencies), and new ones are created
	• Storing and retrieving these dependencies is called artifact management
	• Traditionally you need to setup your own artifact management system
	• CodeArtifact is a secure, scalable, and cost-effective artifact management for
	software development
	• Works with common dependency management tools such as Maven, Gradle,
	npm, yarn, twine, pip, and NuGet
	• Developers and CodeBuild can then retrieve dependencies straight from
	CodeArtifact

AWS CodeStar
	• Unified UI to easily manage software development activities in one place
	• “Quick way” to get started to correctly set-up CodeCommit, CodePipeline,
	CodeBuild, CodeDeploy, Elastic Beanstalk, EC2, etc…
	• Can edit the code ”in-the-cloud” using AWS Cloud9	
	
AWS Cloud9
	• AWS Cloud9 is a cloud IDE (Integrated
	Development Environment) for writing, running
	and debugging code
	• “Classic” IDE (like IntelliJ, Visual Studio Code…)
	are downloaded on a computer before being
	used
	• A cloud IDE can be used within a web browser,
	meaning you can work on your projects from
	your office, home, or anywhere with internet
	with no setup necessary
	• AWS Cloud9 also allows for code collaboration
	in real-time (pair programming)	

AWS Systems Manager (SSM)
	• Helps you manage your EC2 and On-Premises systems at scale
	• Another Hybrid AWS service
	• Get operational insights about the state of your infrastructure
	• Suite of 10+ products
	• Most important features are:
	• Patching automation for enhanced compliance
	• Run commands across an entire fleet of servers
	• Store parameter configuration with the SSM Parameter Store
	• Works for Linux, Windows, MacOS, and Raspberry Pi OS (Raspbian	

Systems Manager – SSM Session Manager
	• Allows you to start a secure shell on your EC2 and
	on-premises servers
	• No SSH access, bastion hosts, or SSH keys
	needed
	• No port 22 needed (better security)
	• Supports Linux, macOS, and Windows
	• Send session log data to S3 or CloudWatch Logs

AWS OpsWorks
	• Chef & Puppet help you perform server configuration automatically, or
	repetitive actions
	• They work great with EC2 & On-Premises VM
	• AWS OpsWorks = Managed Chef & Puppet
	• It’s an alternative to AWS SSM
	• Only provision standard AWS resources:
	• EC2 Instances, Databases, Load Balancers, EBS volumes…
	• In the exam: Chef or Puppet needed => AWS OpsWorks
	
Deployment - Summary
	• CloudFormation: (AWS only)
	• Infrastructure as Code, works with almost all of AWS resources
	• Repeat across Regions & Accounts
	• Beanstalk: (AWS only)
	• Platform as a Service (PaaS), limited to certain programming languages or Docker
	• Deploy code consistently with a known architecture: ex, ALB + EC2 + RDS
	• CodeDeploy (hybrid): deploy & upgrade any application onto servers
	• Systems Manager (hybrid): patch, configure and run commands at scale
	• OpsWorks (hybrid): managed Chef and Puppet in AWS	

Developer Services - Summary
	• CodeCommit: Store code in private git repository (version controlled)
	• CodeBuild: Build & test code in AWS
	• CodeDeploy: Deploy code onto servers
	• CodePipeline: Orchestration of pipeline (from code to build to deploy)
	• CodeArtifact: Store software packages / dependencies on AWS
	• CodeStar: Unified view for allowing developers to do CICD and code
	• Cloud9: Cloud IDE (Integrated Development Environment) with collab
	• AWS CDK: Define your cloud infrastructure using a programming language	

############################################################################################
#######################Section 22 Preparing of Exam 23 min########################
############################################################################################	
ONE
############################################################################################
	#######################Section 23########################
############################################################################################	
DONE

############################################################################################
#######################Section 17 Machine Learning  20 min########################
############################################################################################	

Amazon Rekognition
• Find objects, people, text, scenes in images and videos using ML
• Facial analysis and facial search to do user verification, people counting
• Create a database of “familiar faces” or compare against celebrities
• Use cases:
	• Labeling
	• Content Moderation
	• Text Detection
	• Face Detection and Analysis (gender, age range, emotions…)
	• Face Search and Verification
	• Celebrity Recognition
	• Pathing (ex: for sports game analysis)

Amazon Transcribe
• Automatically convert speech to text
• Uses a deep learning process called automatic speech recognition (ASR) to
convert speech to text quickly and accurately
• Automatically remove Personally Identifiable Information (PII) using Redaction
• Supports Automatic Language Identification for multi-lingual audio
• Use cases:
	• transcribe customer service calls
	• automate closed captioning and subtitling
	• generate metadata for media assets to create


Amazon Polly
• Turn text into lifelike speech using deep learning
• Allowing you to create applications

Amazon Translate
• Natural and accurate language translation
• Amazon Translate allows you to localize content - such as websites and
applications - for international users, and to easily translate large
volumes of text efficiently.


Amazon Lex & Connect
	• Amazon Lex: (same technology that powers Alexa)
	• Automatic Speech Recognition (ASR) to convert speech to text
	• Natural Language Understanding to recognize the intent of text, callers
	• Helps build chatbots, call center bots
• Amazon Connect:
	• Receive calls, create contact flows, cloud-based virtual contact center
	• Can integrate with other CRM systems or AWS
	• No upfront payments, 80% cheaper than traditional contact center solutions

Amazon Comprehend
• For Natural Language Processing – NLP
• Fully managed and serverless service
• Uses machine learning to find insights and relationships in text
• Language of the text
• Extracts key phrases, places, people, brands, or events
• Understands how positive or negative the text is
• Analyzes text using tokenization and parts of speech
• Automatically organizes a collection of text files by topic
• Sample use cases:
	• analyze customer interactions (emails) to find what leads to a positive or negative experience
	• Create and groups articles by topics that Comprehend will uncover


Amazon SageMaker
• Fully managed service for developers / data scientists to build ML models
• Typically, difficult to do all the processes in one place + provision servers
• Machine learning process (simplified): predicting your exam score

Amazon Forecast
• Fully managed service that uses ML to deliver highly accurate forecasts
• Example: predict the future sales of a raincoat
• 50% more accurate than looking at the data itself
• Reduce forecasting time from months to hours
• Use cases: Product Demand Planning, Financial Planning, Resource Planning, …

Amazon Kendra
• Fully managed document search service powered by Machine Learning
• Extract answers from within a document (text, pdf, HTML, PowerPoint, MS Word, FAQs…)
• Natural language search capabilities
• Learn from user interactions/feedback to promote preferred results (Incremental Learning)
• Ability to manually fine-tune search results (importance of data, freshness, custom, …)

Amazon Personalize
• Fully managed ML-service to build apps with real-time personalized recommendations
• Example: personalized product recommendations/re-ranking, customized direct marketing
• Example: User bought gardening tools, provide recommendations on the next one to buy
• Same technology used by Amazon.com
• Integrates into existing websites, applications, SMS, email marketing systems, …
• Implement in days, not months (you don’t need to build, train, and deploy ML solutions)
• Use cases: retail stores, media and entertainment…

Amazon Textract
• Automatically extracts text, handwriting, and data from any scanned
documents using AI and ML
• Extract data from forms and tables
• Read and process any type of document (PDFs, images, …)
• Use cases:
• Financial Services (e.g., invoices, financial reports)
• Healthcare (e.g., medical records, insurance claims)
• Public Sector (e.g., tax forms, ID documents, passports)
Amazon Textract
{
“Document ID”: “123456789-005”,
“Name”: “”,
“SEX”: “F”,
“DOB”: “23.05.1997”,
…
}
analyze result


AWS Machine Learning - Summary
• Rekognition: face detection, labeling, celebrity recognition
• Transcribe: audio to text (ex: subtitles)
• Polly: text to audio
• Translate: translations
• Lex: build conversational bots – chatbots
• Connect: cloud contact center
• Comprehend: natural language processing
• SageMaker: machine learning for every developer and data scientist
• Forecast: build highly accurate forecasts
• Kendra: ML-powered search engine
• Personalize: real-time personalized recommendations
• Textract: detect text and data in documents

############################################################################################
#######################Section 13 Cloud Integration 18min ########################
############################################################################################

Section Introduction
• Synchronous between applications can be problematic if there are
sudden spikes of traffic
• What if you need to suddenly encode 1000 videos but usually it’s 10?
• In that case, it’s better to decouple your applications:
• using SQS: queue model
• using SNS: pub/sub model
• using Kinesis: real-time data streaming model
• These services can scale independently from our application!

Amazon SQS – Standard Queue
• Oldest AWS offering (over 10 years old)
• Fully managed service (~serverless), use to decouple applications
• Scales from 1 message per second to 10,000s per second
• Default retention of messages: 4 days, maximum of 14 days
• No limit to how many messages can be in the queue
• Messages are deleted after they’re read by consumers
• Low latency (<10 ms on publish and receive)
• Consumers share the work to read messages & scale horizontally

Amazon SQS – FIFO Queue
• FIFO = First In First Out (ordering of messages in the queue)
• Messages are processed in order by the consumer

Amazon Kinesis
• For the exam: Kinesis = real-time big data streaming
• Managed service to collect, process, and analyze real-time streaming
data at any scale
• Too detailed for the Cloud Practitioner exam but good to know:
• Kinesis Data Streams: low latency streaming to ingest data at scale from
hundreds of thousands of sources
• Kinesis Data Firehose: load streams into S3, Redshift, ElasticSearch, etc…
• Kinesis Data Analytics: perform real-time analytics on streams using SQL
• Kinesis Video Streams: monitor real-time video streams for analytics or ML


Amazon SNS
• What if you want to send one message to many receivers?
• The “event publishers” only sends message to one SNS topic
• As many “event subscribers” as we want to listen to the SNS topic notifications
• Each subscriber to the topic will get all the messages
• Up to 12,500,000 subscriptions per topic, 100,000 topics limit


Amazon MQ
• SQS, SNS are “cloud-native” services: proprietary protocols from AWS
• Traditional applications running from on-premises may use open protocols
such as: MQTT, AMQP, STOMP, Openwire, WSS
• When migrating to the cloud, instead of re-engineering the application to
use SQS and SNS, we can use Amazon MQ
• Amazon MQ is a managed message broker service for
• Amazon MQ doesn’t “scale” as much as SQS / SNS
• Amazon MQ runs on servers, can run in Multi-AZ with failover
• Amazon MQ has both queue feature (~SQS) and topic features (~SNS)

Integration Section – Summary
• SQS:
• Queue service in AWS
• Multiple Producers, messages are kept up to 14 days
• Multiple Consumers share the read and delete messages when done
• Used to decouple applications in AWS
• SNS:
• Notification service in AWS
• Subscribers: Email, Lambda, SQS, HTTP, Mobile…
• Multiple Subscribers, send all messages to all of them
• No message retention
• Kinesis: real-time data streaming, persistence and analysis
• Amazon MQ: managed message broker for ActiveMQ and RabbitMQ in the
cloud (MQTT, AMQP.. protocols)

############################################################################################
#######################Section 19 Advanced Identity  9 min########################
############################################################################################	

AWS STS (Security Token Service)
	• Enables you to create temporary, limitedprivileges
	credentials to access your AWS
	resources
	• Short-term credentials: you configure
	expiration period
• Use cases
	• Identity federation: manage user identities in
	external systems, and provide them with STS
	tokens to access AWS resources
	• IAM Roles for cross/same account access
	• IAM Roles for Amazon EC2: provide temporary
	credentials for EC2 instances to access AWS
	resources


Amazon Cognito (simplified)
	• Identity for your Web and Mobile applications users (potentially millions)
	• Instead of creating them an IAM user, you create a user in Cognito (login with fb google and other social media)


What is Microsoft Active Directory (AD)?
	• Found on any Windows Server
	with AD Domain Services
	• Database of objects: User
	Accounts, Computers, Printers,
	File Shares, Security Groups
	• Centralized security
	management, create account,
	assign permissions

AWS Directory Services
	• AWS Managed Microsoft AD
	• Create your own AD in AWS, manage users
	locally, supports MFA
	• Establish “trust” connections with your onpremise
	AD
• AD Connector
	• Directory Gateway (proxy) to redirect to onpremise
	AD, supports MFA
	• Users are managed on the on-premise AD
• Simple AD
	• AD-compatible managed directory on AWS
	• Cannot be joined with on-premise AD


AWS IAM Identity Center
(successor to AWS Single Sign-On)
	• One login (single sign-on) for all your
	• AWS accounts in AWS Organizations
	• Business cloud applications (e.g., Salesforce, Box, Microsoft 365, …)
	• SAML2.0-enabled applications
	• EC2 Windows Instances
• Identity providers
	• Built-in identity store in IAM Identity Center
	• 3rd party: Active Directory (AD), OneLogin, Okta…


Advanced Identity - Summary
• IAM
	• Identity and Access Management inside your AWS account
	• For users that you trust and belong to your company
• Organizations: Manage multiple accounts
• Security Token Service (STS): temporary, limited-privileges credentials to access AWS resources
• Cognito: create a database of users for your mobile & web applications
• Directory Services: integrate Microsoft Active Directory in AWS
• IAM Identity Center: one login for multiple AWS accounts & applications



















############################################################################################
#######################Section 20 Other Services  29 min########################
############################################################################################	



############################################################################################
#######################Section 15 VPC and Networking  33 min ########################
############################################################################################	


############################################################################################
#######################Section 14 Cloud Monitoring  40 min ########################
############################################################################################	


############################################################################################
#######################DATABASE ANALYTICS 48mins########################
############################################################################################


############################################################################################
#######################Section 12 Leveraging AWS Global Infrastructure 48########################
############################################################################################	


############################################################################################
#######################Section 16 Security Compliance  54 min########################
############################################################################################	



############################################################################################
#######################Section 18 Account Management Billing and Support  88 min########################
############################################################################################	




############################################################################################
#######################Section 21 AWS Architeure and Ecosystem  52 min########################
############################################################################################	


